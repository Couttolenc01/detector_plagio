import streamlit as st
import joblib
import os
import numpy as np
import re

# --------------------------
# Configuraci√≥n de p√°gina
# --------------------------
st.set_page_config(
    page_title="Detector de Plagio BERT",
    page_icon="ü§ñ",
    layout="wide"
)

# --------------------------
# Cargar modelo
# --------------------------
@st.cache_resource
def load_model():
    if not os.path.exists("modelo_plagio_rf.pkl"):
        st.error("‚ùå Modelo no encontrado: modelo_plagio_rf.pkl")
        st.info("üí° Ejecuta: `python train_clasificador_rf.py` para generar el modelo.")
        st.stop()
    
    model_package = joblib.load("modelo_plagio_rf.pkl")
    return model_package

try:
    model_package = load_model()
    encoder = model_package['encoder']
    classifier = model_package['classifier']
    feature_names = model_package['feature_names']
    classes = model_package.get('classes', ['non', 'light', 'cut'])
    model_info = model_package.get('model_info', {})
    modelo_cargado = True
except Exception as e:
    st.error(f"‚ùå Error al cargar el modelo: {e}")
    modelo_cargado = False

# --------------------------
# Funciones auxiliares
# --------------------------

def compute_similarity(emb1, emb2):
    """Calcula similitud coseno entre embeddings BERT"""
    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

def extract_features(texto1, texto2, emb1, emb2):
    """Extrae todas las caracter√≠sticas del par de textos"""
    
    # 1. Similitud sem√°ntica BERT
    sim_coseno = compute_similarity(emb1, emb2)
    
    # 2. Longitud
    len1, len2 = len(texto1), len(texto2)
    len_ratio = min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 0
    len_diff_rel = abs(len1 - len2) / max(len1, len2) if max(len1, len2) > 0 else 0
    
    # 3. L√©xicas
    words1 = texto1.lower().split()
    words2 = texto2.lower().split()
    set1 = set(words1)
    set2 = set(words2)
    
    common_words = set1.intersection(set2)
    union_words = set1.union(set2)
    
    jaccard_words = len(common_words) / len(union_words) if union_words else 0
    overlap_coef = len(common_words) / min(len(set1), len(set2)) if min(len(set1), len(set2)) > 0 else 0
    
    # 4. N-gramas
    bigrams1 = set(zip(words1[:-1], words1[1:])) if len(words1) > 1 else set()
    bigrams2 = set(zip(words2[:-1], words2[1:])) if len(words2) > 1 else set()
    jaccard_bigrams = len(bigrams1.intersection(bigrams2)) / len(bigrams1.union(bigrams2)) if bigrams1.union(bigrams2) else 0
    
    trigrams1 = set(zip(words1[:-2], words1[1:-1], words1[2:])) if len(words1) > 2 else set()
    trigrams2 = set(zip(words2[:-2], words2[1:-1], words2[2:])) if len(words2) > 2 else set()
    jaccard_trigrams = len(trigrams1.intersection(trigrams2)) / len(trigrams1.union(trigrams2)) if trigrams1.union(trigrams2) else 0
    
    # 5. Caracteres
    char_bigrams1 = set([texto1[i:i+2] for i in range(len(texto1)-1)])
    char_bigrams2 = set([texto2[i:i+2] for i in range(len(texto2)-1)])
    jaccard_char_bigrams = len(char_bigrams1.intersection(char_bigrams2)) / len(char_bigrams1.union(char_bigrams2)) if char_bigrams1.union(char_bigrams2) else 0
    
    # 6. Estructurales
    num_sentences1 = len(re.split(r'[.!?]+', texto1))
    num_sentences2 = len(re.split(r'[.!?]+', texto2))
    sentence_ratio = min(num_sentences1, num_sentences2) / max(num_sentences1, num_sentences2) if max(num_sentences1, num_sentences2) > 0 else 0
    
    vocab_size1 = len(set1)
    vocab_size2 = len(set2)
    vocab_ratio = min(vocab_size1, vocab_size2) / max(vocab_size1, vocab_size2) if max(vocab_size1, vocab_size2) > 0 else 0
    
    ttr1 = vocab_size1 / len(words1) if words1 else 0
    ttr2 = vocab_size2 / len(words2) if words2 else 0
    ttr_diff = abs(ttr1 - ttr2)
    
    features = {
        'sim_coseno': sim_coseno,
        'len_ratio': len_ratio,
        'len_diff_rel': len_diff_rel,
        'jaccard_words': jaccard_words,
        'overlap_coef': overlap_coef,
        'jaccard_bigrams': jaccard_bigrams,
        'jaccard_trigrams': jaccard_trigrams,
        'jaccard_char_bigrams': jaccard_char_bigrams,
        'sentence_ratio': sentence_ratio,
        'vocab_ratio': vocab_ratio,
        'ttr_diff': ttr_diff,
    }
    
    return features

def predecir_plagio(original, sospechoso):
    """Predice plagio usando BERT + Random Forest"""
    
    # Generar embeddings con BERT
    emb1 = encoder.encode([original])[0]
    emb2 = encoder.encode([sospechoso])[0]
    
    # Extraer caracter√≠sticas
    features = extract_features(original, sospechoso, emb1, emb2)
    
    # Preparar vector
    X = np.array([list(features.values())])
    
    # Predecir
    prediction = classifier.predict(X)[0]
    probas = classifier.predict_proba(X)[0]
    
    # Obtener confianza
    class_names = classifier.classes_
    pred_idx = np.where(class_names == prediction)[0][0]
    confidence = probas[pred_idx]
    
    return prediction, confidence, features, probas, class_names

# --------------------------
# Interfaz principal
# --------------------------

st.title("ü§ñ Detector de Plagio ‚Äì BERT + Machine Learning")

st.markdown("""
Sistema profesional de detecci√≥n de plagio usando **BERT (RoBERTa Large)** combinado con **Random Forest**.  
Analiza similitud sem√°ntica profunda y caracter√≠sticas l√©xicas/estructurales.
""")

# Categor√≠as
col1, col2, col3 = st.columns(3)
with col1:
    st.success("**üü¢ NON**  \nNo hay plagio  \nTextos diferentes")
with col2:
    st.warning("**üü° LIGHT**  \nPar√°frasis ligera  \nReformulaci√≥n superficial")
with col3:
    st.error("**üî¥ CUT**  \nCopia directa  \nCambios m√≠nimos")

st.divider()

if not modelo_cargado:
    st.warning("‚ö†Ô∏è Modelo no cargado. Entrena primero con: `python train_clasificador_rf.py`")
    st.stop()

# Info del modelo
with st.expander("‚ÑπÔ∏è Informaci√≥n del modelo BERT"):
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Arquitectura:**")
        st.write(f"- Encoder: RoBERTa Large")
        st.write(f"- Dimensiones: {model_info.get('encoder_dim', 1024)}")
        st.write(f"- Clasificador: Random Forest")
        st.write(f"- √Årboles: {model_info.get('n_estimators', 200)}")
    
    with col2:
        st.write("**Performance:**")
        if 'accuracy_test' in model_info:
            st.write(f"- Accuracy (Test): {model_info['accuracy_test']:.1%}")
        if 'accuracy_full' in model_info:
            st.write(f"- Accuracy (Full): {model_info['accuracy_full']:.1%}")
        st.write(f"- Features: {len(feature_names)}")
        st.write(f"- Clases: {', '.join(classes)}")

st.divider()

# Entrada de textos
st.subheader("üìù Ingresa los textos a comparar")

col1, col2 = st.columns(2)

with col1:
    texto_original = st.text_area(
        "üìÑ Texto Original",
        height=300,
        placeholder="Pega aqu√≠ el texto original...",
        help="El texto de referencia contra el cual se comparar√°"
    )

with col2:
    texto_sospechoso = st.text_area(
        "üîç Texto a Verificar",
        height=300,
        placeholder="Pega aqu√≠ el texto a verificar...",
        help="El texto que quieres analizar para detectar plagio"
    )

# Bot√≥n de an√°lisis
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    analizar_btn = st.button("üîç Analizar Plagio", type="primary", use_container_width=True)

if analizar_btn:
    if not texto_original.strip() or not texto_sospechoso.strip():
        st.error("‚ùå Por favor ingresa ambos textos para realizar el an√°lisis.")
    else:
        with st.spinner("üßÆ Analizando con BERT y Random Forest..."):
            prediccion, confianza, features, probas, class_names = predecir_plagio(
                texto_original, texto_sospechoso
            )

        st.divider()
        st.subheader("üìä Resultado del An√°lisis")

        # Resultado principal
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            etiquetas = {
                "non": ("‚úÖ NO HAY PLAGIO", "success", "Los textos son suficientemente diferentes."),
                "light": ("‚ö†Ô∏è PLAGIO LIGERO", "warning", "Par√°frasis superficial detectada."),
                "cut": ("üö® COPIA DIRECTA", "error", "Alta similitud - posible plagio.")
            }
            
            label_text, color, descripcion = etiquetas.get(prediccion, (prediccion, "info", ""))
            
            if color == "success":
                st.success(f"### {label_text}")
            elif color == "warning":
                st.warning(f"### {label_text}")
            elif color == "error":
                st.error(f"### {label_text}")
            
            st.caption(descripcion)
        
        with col2:
            st.metric(
                "Confianza",
                f"{confianza*100:.1f}%",
                help="Probabilidad de la predicci√≥n"
            )
        
        with col3:
            # Emoji seg√∫n resultado
            emoji_map = {"non": "‚úÖ", "light": "‚ö†Ô∏è", "cut": "üö®"}
            st.markdown(f"<div style='text-align: center; font-size: 80px;'>{emoji_map.get(prediccion, '‚ùì')}</div>", unsafe_allow_html=True)
        
        # Distribuci√≥n de probabilidades
        st.markdown("### üìä Distribuci√≥n de Probabilidades")
        
        prob_cols = st.columns(len(class_names))
        for i, clase in enumerate(class_names):
            with prob_cols[i]:
                emoji = {"non": "üü¢", "light": "üü°", "cut": "üî¥"}
                prob = probas[i] * 100
                
                # Color seg√∫n probabilidad
                if prob >= 50:
                    color = "success" if clase == "non" else ("error" if clase == "cut" else "warning")
                else:
                    color = "secondary"
                
                st.metric(
                    f"{emoji.get(clase, '‚Ä¢')} {clase.upper()}",
                    f"{prob:.1f}%"
                )
                st.progress(probas[i])
        
        # Caracter√≠sticas principales
        st.markdown("### üîç An√°lisis Detallado")
        
        tab1, tab2, tab3 = st.tabs(["üß† Similitud Sem√°ntica", "üìù Caracter√≠sticas L√©xicas", "üìè Caracter√≠sticas Estructurales"])
        
        with tab1:
            st.markdown("#### Similitud BERT (RoBERTa Large)")
            sim = features['sim_coseno']
            st.progress(sim, text=f"Similitud Coseno: {sim:.3f}")
            
            if sim >= 0.8:
                st.error("üö® Similitud muy alta - Los textos son casi id√©nticos sem√°nticamente")
            elif sim >= 0.6:
                st.warning("‚ö†Ô∏è Similitud considerable - Par√°frasis o contenido relacionado")
            elif sim >= 0.4:
                st.info("‚ÑπÔ∏è Similitud moderada - Algunos temas en com√∫n")
            else:
                st.success("‚úÖ Similitud baja - Textos diferentes")
            
            st.caption("Mide la similitud sem√°ntica profunda usando embeddings de 1024 dimensiones")
        
        with tab2:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Jaccard (palabras)", f"{features['jaccard_words']:.3f}")
                st.caption("Palabras en com√∫n")
                
            with col2:
                st.metric("Jaccard (bigramas)", f"{features['jaccard_bigrams']:.3f}")
                st.caption("Pares de palabras")
                
            with col3:
                st.metric("Jaccard (trigramas)", f"{features['jaccard_trigrams']:.3f}")
                st.caption("Tr√≠os de palabras")
            
            st.markdown("---")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Overlap Coefficient", f"{features['overlap_coef']:.3f}")
            with col2:
                st.metric("Jaccard (char bigrams)", f"{features['jaccard_char_bigrams']:.3f}")
        
        with tab3:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Ratio Longitud", f"{features['len_ratio']:.3f}")
                st.caption("Similitud en extensi√≥n")
                
            with col2:
                st.metric("Ratio Oraciones", f"{features['sentence_ratio']:.3f}")
                st.caption("Estructura similar")
                
            with col3:
                st.metric("Ratio Vocabulario", f"{features['vocab_ratio']:.3f}")
                st.caption("Riqueza l√©xica")
            
            st.markdown("---")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Dif. Longitud (rel)", f"{features['len_diff_rel']:.3f}")
            with col2:
                st.metric("Dif. TTR", f"{features['ttr_diff']:.3f}")
                st.caption("Type-Token Ratio")
        
        # Interpretaci√≥n
        with st.expander("üí° Interpretaci√≥n del Resultado"):
            if prediccion == "non":
                st.info("""
                **‚úÖ No se detect√≥ plagio.**
                
                Los textos presentan diferencias significativas tanto en contenido sem√°ntico como en caracter√≠sticas l√©xicas.
                La similitud BERT y las m√©tricas de n-gramas est√°n por debajo de los umbrales de plagio.
                
                **Conclusi√≥n:** Los documentos son suficientemente diferentes.
                """)
            elif prediccion == "light":
                st.warning("""
                **‚ö†Ô∏è Plagio ligero detectado.**
                
                Los textos comparten ideas y estructuras similares con reformulaci√≥n superficial.
                Se detect√≥ par√°frasis que mantiene el contenido original con cambios menores.
                
                **Recomendaci√≥n:** Verificar fuentes y a√±adir citas apropiadas. Considerar reescribir con mayor originalidad.
                """)
            else:  # cut
                st.error("""
                **üö® Copia directa detectada.**
                
                Los textos son pr√°cticamente id√©nticos o tienen cambios muy m√≠nimos.
                Alta similitud sem√°ntica y l√©xica indica copia sustancial del contenido.
                
                **ADVERTENCIA:** Esto constituye plagio acad√©mico. Se debe reescribir completamente con palabras propias y citar correctamente las fuentes.
                """)
        
        # Advertencias
        if confianza < 0.6:
            st.info("‚ÑπÔ∏è **Nota:** La confianza del modelo es moderada. El caso est√° en una zona fronteriza entre categor√≠as. Se recomienda revisi√≥n manual.")

# Footer
st.divider()
st.caption("ü§ñ Powered by BERT (RoBERTa Large) + Random Forest | Desarrollado con Streamlit")

# Sidebar con info adicional
with st.sidebar:
    st.header("‚ÑπÔ∏è Acerca del Sistema")
    
    st.markdown("""
    ### ü§ñ Tecnolog√≠a BERT
    
    Este detector utiliza **RoBERTa Large**, una versi√≥n optimizada de BERT con:
    
    - üß† **355M par√°metros**
    - üìä **1024 dimensiones** por embedding
    - üåê **Comprensi√≥n sem√°ntica profunda**
    
    ### üå≤ Random Forest
    
    Clasificador ensemble que combina:
    - 200 √°rboles de decisi√≥n
    - 11 caracter√≠sticas diferentes
    - Balanceo de clases autom√°tico
    
    ### üìè Caracter√≠sticas Analizadas
    
    1. **Sem√°nticas:** Similitud BERT
    2. **L√©xicas:** Jaccard (palabras, n-gramas, caracteres)
    3. **Estructurales:** Longitud, oraciones, vocabulario
    
    ### üéØ Categor√≠as
    
    - **NON:** Sin plagio
    - **LIGHT:** Par√°frasis ligera
    - **CUT:** Copia directa
    """)
    
    st.divider()
    
    st.markdown("""
    ### üí° Consejos de Uso
    
    - Ingresa textos de al menos 100 caracteres
    - Resultados m√°s precisos con textos m√°s largos
    - La confianza >60% es confiable
    - Revisa manualmente casos fronterizos
    """)