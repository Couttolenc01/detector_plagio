ğŸ§  Detector de Plagio con Embeddings SemÃ¡nticos (BERT / RoBERTa)

Este proyecto implementa un sistema de detecciÃ³n de similitud entre textos utilizando embeddings semÃ¡nticos generados por modelos avanzados como RoBERTa (vÃ­a sentence-transformers).

El objetivo es identificar distintos niveles de plagio incluso cuando existe parÃ¡frasis moderada o fuerte, algo que tÃ©cnicas tradicionales como TF-IDF no pueden lograr.

El sistema permite cargar textos desde archivos .txt, generar un dataset dinÃ¡mico y calcular similitud entre pares de textos mediante cosine similarity.

â¸»

ğŸš€ Funcionalidades principales
	â€¢	Lectura dinÃ¡mica de mÃºltiples archivos .txt desde una carpeta.
	â€¢	ConstrucciÃ³n automÃ¡tica de un dataset a partir de un archivo pares_textos.csv.
	â€¢	GeneraciÃ³n de embeddings semÃ¡nticos usando RoBERTa Large.
	â€¢	CÃ¡lculo de similitud con cosine similarity.
	â€¢	ClasificaciÃ³n conceptual de los niveles de plagio:
	â€¢	ğŸ”´ Plagio alto (0.85 â€“ 1.00)
	â€¢	ğŸŸ  Plagio moderado (0.70 â€“ 0.85)
	â€¢	ğŸŸ¡ Plagio leve (0.55 â€“ 0.70)
	â€¢	ğŸŸ¢ No plagio (0.00 â€“ 0.45)
	â€¢	ExportaciÃ³n de resultados a CSV.

â¸»

ğŸ“¦ Estructura del proyecto

detector_plagio/
â”œâ”€â”€ textos/                        # Carpeta con archivos .txt
â”œâ”€â”€ pares_textos.csv               # Define quÃ© archivos se comparan entre sÃ­
â”œâ”€â”€ construir_dataset_desde_archivos.py
â”œâ”€â”€ calcular_similitud_bert.py
â”œâ”€â”€ dataset_manual.py              # (Opcional) Dataset estÃ¡tico para pruebas
â”œâ”€â”€ resultado_similitud_archivos.csv
â”œâ”€â”€ resultado_similitud.csv
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


â¸»

ğŸ›  InstalaciÃ³n y ejecuciÃ³n

1ï¸âƒ£ Clonar el repositorio

git clone https://github.com/Couttolenc01/detector_plagio.git
cd detector_plagio


â¸»

2ï¸âƒ£ Crear un entorno virtual

macOS / Linux

python3 -m venv venv

Windows

python -m venv venv


â¸»

3ï¸âƒ£ Activar el entorno virtual

macOS / Linux

source venv/bin/activate

Windows (PowerShell)

venv\Scripts\activate


â¸»

4ï¸âƒ£ Instalar dependencias

pip install -r requirements.txt


â¸»

5ï¸âƒ£ (Opcional) Crear un archivo .env si deseas usar API

touch .env

Y dentro escribir:

OPENAI_API_KEY=TU_API_KEY


â¸»

6ï¸âƒ£ Construir dataset desde archivos .txt

Este archivo genera automÃ¡ticamente dataset_plagio_archivos.csv leyendo tus textos.

python construir_dataset_desde_archivos.py


â¸»

7ï¸âƒ£ Calcular la similitud con embeddings BERT

python calcular_similitud_bert.py

Los resultados aparecerÃ¡n en:

resultado_similitud_archivos.csv


â¸»

ğŸ§ª Ejemplo de salida

  tipo_par       etiqueta          sim_coseno
0 literal       plagio_alto        0.9400
1 moderado      plagio_moderado    0.9149
2 fuerte        plagio_leve        0.8508
3 no_rel        no_plagio          0.3720

La similitud se interpreta asÃ­:
	â€¢	0.94 â†’ Plagio alto (casi igual)
	â€¢	0.91 â†’ Plagio moderado (parÃ¡frasis leve)
	â€¢	0.85 â†’ ParÃ¡frasis fuerte
	â€¢	0.37 â†’ Textos no relacionados

â¸»

ğŸ§  Â¿CÃ³mo funciona este sistema?
	1.	Embeddings semÃ¡nticos: Convertimos cada texto en un vector de alta dimensiÃ³n usando un modelo pre-entrenado (RoBERTa Large).
	2.	ComparaciÃ³n vectorial: Medimos quÃ© tan similares son los vectores mediante cosine similarity.
	3.	InterpretaciÃ³n: Valores cercanos a 1.0 indican alta similitud; valores cercanos a 0.0 indican que los textos no se parecen.

No se realiza entrenamiento propio: el sistema usa un modelo ya pre-entrenado en millones de pares de oraciones.
